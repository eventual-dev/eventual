{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Eventual \u00b6 Eventual aims to provide strong guarantees while being safe and easy to use. It's not an easy task so eventual is pluggable. Check out getting started.","title":"Home"},{"location":"#eventual","text":"Eventual aims to provide strong guarantees while being safe and easy to use. It's not an easy task so eventual is pluggable. Check out getting started.","title":"Eventual"},{"location":"design_and_internals/placeholder/","text":"","title":"Placeholder"},{"location":"design_and_internals/retry_behavior/","text":"Thoughts on retrying \u00b6 Suppose a service called A produces a message M. A service called B wants to send an email for every such message M that it gets. B uses a REST API to submit letters to be sent. What happens if that API is not available at the moment that B gets M and tries to handle it? In the client-server model B doesn't get a message from A, but instead A sends a request to B. If B can't handle the request, it indicates failure to A by sending an appropriate HTTP response code. In this case it's on A to retry whatever it's trying to achieve via B at a later time. But how do we deal with these kinds of failures when messages are involved? One of the great advantages of message driven systems is that A doesn't have to know anything about B. So it would be unwise to involve A in any way in case B fails to handle M. Furthermore, one of the design goals of this particular library is to never lose a message, which means B can't just drop M and move on. M has to be stored somewhere where B (and only B, because other services might not have failed to handle M) has access to it and then M has to be retrieved and retired by B. Taking into account that B may actually be deployed as multiple pods there are two such places: B's database B's queue One of the primary concerns in designing the retry flow is to make sure that it's not possible to overwhelm the system. If a retry operation can lead to a cascade of errors then the entire system can collapse. It's also important to actually delay a retry attempt, to give the system a chance to recover. Retrying over and over immediately can also lead to a collapse. Queue \u00b6 Let's explore the queue option. There are two points of interest: Dispatcher checking if M was already handled by B, B marking M as handled with respect to a particular guarantee. If M was already handled then dispatcher acknowledges the message as if it was handled (because it was) and doesn't in fact dispatch it. If B raises an exception during the handling of M, M is scheduled to be sent by B at some point in the future. It will be sent as is to everyone, as if it was sent by A again. If there are other services besides B that failed to handle M, they will resend it to. The case of several services failing to handle a message is actually common, that happens when a common dependency is unavailable. There is always a possiblity that M will be sent to the queue multiple times, this is not directly related to retries. We have idempotency keys and different guarantees exactly for that. Every service that handled M successfully the first time will ignore it. But we have a situation in which a failure can lead from one M message to as many M messages as there are services that failed, so we have to be careful to prevent any possibility that the number failures will grow exponentially. Sequential processing \u00b6 Suppose that B gets M two times (M1 and M2) sequentially meaning first it runs points 1 and 2 for M1 and only then does the same for M2. In that case dispatcher will silently acknowledge M2 and move on. Concurrent processing \u00b6 Suppose now that B gets M two times (M1 and M2) concurrently meaning that before it runs 2 for M1 it runs 1 for M2. Handling M1 and M2 becomes a race. The race is won by the thread that first marks M as handled in the database.","title":"Thoughts on retrying"},{"location":"design_and_internals/retry_behavior/#thoughts-on-retrying","text":"Suppose a service called A produces a message M. A service called B wants to send an email for every such message M that it gets. B uses a REST API to submit letters to be sent. What happens if that API is not available at the moment that B gets M and tries to handle it? In the client-server model B doesn't get a message from A, but instead A sends a request to B. If B can't handle the request, it indicates failure to A by sending an appropriate HTTP response code. In this case it's on A to retry whatever it's trying to achieve via B at a later time. But how do we deal with these kinds of failures when messages are involved? One of the great advantages of message driven systems is that A doesn't have to know anything about B. So it would be unwise to involve A in any way in case B fails to handle M. Furthermore, one of the design goals of this particular library is to never lose a message, which means B can't just drop M and move on. M has to be stored somewhere where B (and only B, because other services might not have failed to handle M) has access to it and then M has to be retrieved and retired by B. Taking into account that B may actually be deployed as multiple pods there are two such places: B's database B's queue One of the primary concerns in designing the retry flow is to make sure that it's not possible to overwhelm the system. If a retry operation can lead to a cascade of errors then the entire system can collapse. It's also important to actually delay a retry attempt, to give the system a chance to recover. Retrying over and over immediately can also lead to a collapse.","title":"Thoughts on retrying"},{"location":"design_and_internals/retry_behavior/#queue","text":"Let's explore the queue option. There are two points of interest: Dispatcher checking if M was already handled by B, B marking M as handled with respect to a particular guarantee. If M was already handled then dispatcher acknowledges the message as if it was handled (because it was) and doesn't in fact dispatch it. If B raises an exception during the handling of M, M is scheduled to be sent by B at some point in the future. It will be sent as is to everyone, as if it was sent by A again. If there are other services besides B that failed to handle M, they will resend it to. The case of several services failing to handle a message is actually common, that happens when a common dependency is unavailable. There is always a possiblity that M will be sent to the queue multiple times, this is not directly related to retries. We have idempotency keys and different guarantees exactly for that. Every service that handled M successfully the first time will ignore it. But we have a situation in which a failure can lead from one M message to as many M messages as there are services that failed, so we have to be careful to prevent any possibility that the number failures will grow exponentially.","title":"Queue"},{"location":"design_and_internals/retry_behavior/#sequential-processing","text":"Suppose that B gets M two times (M1 and M2) sequentially meaning first it runs points 1 and 2 for M1 and only then does the same for M2. In that case dispatcher will silently acknowledge M2 and move on.","title":"Sequential processing"},{"location":"design_and_internals/retry_behavior/#concurrent-processing","text":"Suppose now that B gets M two times (M1 and M2) concurrently meaning that before it runs 2 for M1 it runs 1 for M2. Handling M1 and M2 becomes a race. The race is won by the thread that first marks M as handled in the database.","title":"Concurrent processing"},{"location":"getting_started/work_unit/","text":"Unit of work \u00b6 Unit of work is an abstraction that represents an atomic operation \u2013 something that either happens entirely (as a unit) or does not happen at all. If you are familiar with database transactions then you are already familiar with the concept of unit of work. It's useful to define such an abstraction because it gives way to multiple implementations, which makes the concept more broad than just a database transaction. Unit of work can represent any kind of work (not necessarily involving saving data to disk). A particular implementation can even have semantics that slightly differ from a transaction in its traditional sense. Creating units of work \u00b6 A natural way to define a unit of work in Python is via a context manager. Every implementation of WorkUnit has a context manager that yields a unit of work instance upon entry: async with WorkUnit . create () as work_unit : ... Note The code above will not work as is, because WorkUnit is an abstract class. You will have to use an implementation that suits your use case, e.g. eventual-tortoise . Be careful about creating nested units of work: async with WorkUnit . create () as work_unit : async with WorkUnit . create () as sub_work_unit : ... Each particular implementation is free to handle such usages differently. Generally speaking, think twice about what you are trying to achieve with nesting. Tip Chances are your application does not have a clear layered structure , which can lead to messy and rigid code. Committing work \u00b6 Here is how you commit your unit of work: async with WorkUnit . create () as work_unit : ... async work_unit . commit () ... All this does is actually marks your unit of work to be committed upon the exit from the context manager. This means that the call doesn't have to be the last thing you do in the context manager block and that the operation is idempotent (doing it any number of times is the same as doing it once). Warning Nothing is committed by default. You have to explicitly signify that you want to commit a unit of work. If an unhandled exception reached the unit of work context manager then work will not be committed. This can happen for a number of reasons including you raising an exception or a particular WorkUnit implementation failing to actually commit the work. Any such exceptions are reraised for you to deal with them. Interrupting work \u00b6 You can explicitly interrupt a unit of work by raising a InterruptWork exception: async with WorkUnit . create () as work_unit : ... raise InterruptWork ... This exception is special, because it's suppressed by the unit of work context manager. Suppressing this exception in your code can lead to unwanted work being committed, so always reraise it. You can interrupt a unit of work by rolling it back: async with WorkUnit . create () as work_unit : ... async work_unit . rollback () ... Note Rolling back is equivalent to raising InterruptWork , in fact, it is how rolling back works, so anything that comes after it in the context manager block is not executed. Checking if unit of work was committed \u00b6 After the context manager block is over you can check if work was successfully committed or not: async with WorkUnit . create () as work_unit : ... async work_unit . rollback () ... assert not work_unit . committed Warning Checking if unit of work was committed inside the context manager block doesn't make sense and is discouraged. The return value of the check is undefined.","title":"Unit of work"},{"location":"getting_started/work_unit/#unit-of-work","text":"Unit of work is an abstraction that represents an atomic operation \u2013 something that either happens entirely (as a unit) or does not happen at all. If you are familiar with database transactions then you are already familiar with the concept of unit of work. It's useful to define such an abstraction because it gives way to multiple implementations, which makes the concept more broad than just a database transaction. Unit of work can represent any kind of work (not necessarily involving saving data to disk). A particular implementation can even have semantics that slightly differ from a transaction in its traditional sense.","title":"Unit of work"},{"location":"getting_started/work_unit/#creating-units-of-work","text":"A natural way to define a unit of work in Python is via a context manager. Every implementation of WorkUnit has a context manager that yields a unit of work instance upon entry: async with WorkUnit . create () as work_unit : ... Note The code above will not work as is, because WorkUnit is an abstract class. You will have to use an implementation that suits your use case, e.g. eventual-tortoise . Be careful about creating nested units of work: async with WorkUnit . create () as work_unit : async with WorkUnit . create () as sub_work_unit : ... Each particular implementation is free to handle such usages differently. Generally speaking, think twice about what you are trying to achieve with nesting. Tip Chances are your application does not have a clear layered structure , which can lead to messy and rigid code.","title":"Creating units of work"},{"location":"getting_started/work_unit/#committing-work","text":"Here is how you commit your unit of work: async with WorkUnit . create () as work_unit : ... async work_unit . commit () ... All this does is actually marks your unit of work to be committed upon the exit from the context manager. This means that the call doesn't have to be the last thing you do in the context manager block and that the operation is idempotent (doing it any number of times is the same as doing it once). Warning Nothing is committed by default. You have to explicitly signify that you want to commit a unit of work. If an unhandled exception reached the unit of work context manager then work will not be committed. This can happen for a number of reasons including you raising an exception or a particular WorkUnit implementation failing to actually commit the work. Any such exceptions are reraised for you to deal with them.","title":"Committing work"},{"location":"getting_started/work_unit/#interrupting-work","text":"You can explicitly interrupt a unit of work by raising a InterruptWork exception: async with WorkUnit . create () as work_unit : ... raise InterruptWork ... This exception is special, because it's suppressed by the unit of work context manager. Suppressing this exception in your code can lead to unwanted work being committed, so always reraise it. You can interrupt a unit of work by rolling it back: async with WorkUnit . create () as work_unit : ... async work_unit . rollback () ... Note Rolling back is equivalent to raising InterruptWork , in fact, it is how rolling back works, so anything that comes after it in the context manager block is not executed.","title":"Interrupting work"},{"location":"getting_started/work_unit/#checking-if-unit-of-work-was-committed","text":"After the context manager block is over you can check if work was successfully committed or not: async with WorkUnit . create () as work_unit : ... async work_unit . rollback () ... assert not work_unit . committed Warning Checking if unit of work was committed inside the context manager block doesn't make sense and is discouraged. The return value of the check is undefined.","title":"Checking if unit of work was committed"},{"location":"reference/placeholder/","text":"","title":"Placeholder"}]}